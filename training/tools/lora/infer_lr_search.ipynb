{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33fe6b-7e27-4514-a8b5-9373738e5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
    "import torch\n",
    "import os\n",
    "from lora_diffusion import tune_lora_scale, patch_pipe\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea68b4e-0263-4531-9415-40ad959197db",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<s1> drinking a beer\"\n",
    "model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "file_path = os.path.abspath(\"\")\n",
    "lr_path = os.path.join(file_path, \"lr_search_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3386808-d473-4090-832e-b172c4ab6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\n",
    "    \"cuda\"\n",
    ")\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "torch.manual_seed(0)\n",
    "image = pipe(prompt, num_inference_steps=25, guidance_scale=9).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1bda86-1531-4eed-af26-96729c6224b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_grid(images, rows, cols, title):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 6))\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        ax.imshow(images[i])\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1bd90f-52a8-413e-bc11-dbf2ba93d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(lr_path)\n",
    "for item in files:\n",
    "    item_path = os.path.join(lr_path, item)\n",
    "    print(item_path)\n",
    "    tensors_path = os.path.join(item_path, \"step_100.safetensors\")\n",
    "    if os.path.exists(tensors_path):\n",
    "        patch_pipe(\n",
    "            pipe,\n",
    "            tensors_path,\n",
    "            patch_text=True,\n",
    "            patch_ti=True,\n",
    "            patch_unet=True,\n",
    "        )\n",
    "\n",
    "        tune_lora_scale(pipe.unet, 1.0)\n",
    "        tune_lora_scale(pipe.text_encoder, 1.0)\n",
    "\n",
    "        torch.manual_seed(0)\n",
    "        images = [pipe(prompt, num_inference_steps=25, guidance_scale=9).images[0] for _ in range(2)]\n",
    "        display_grid(images, 1, 2, item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
